# preprocessor.py

import os
import copy
import argparse
import hashlib
import random

import numpy as np
import pandas as pd
import torch
from torch.utils.data import Dataset
from collections import deque

from atoms_encoding import ATOM_DICT
from randomizer import *

class OCNMoleculeDataset(Dataset):
    '''
    Custom dataset for molecules designed for use with a Perceiver model.
    
    First, all original molecule CSV files are processed and stored.
    Then, a fixed number of 16-atom samples (specified by dataset_length) are precomputed.
    
    Each 16-atom sample is generated by:
      1. Randomly selecting one of the processed molecules.
      2. Logging the v-value (number of penta-cycles) from the filename.
      3. Optionally applying augmentations to the molecule.
      4. Randomly sampling 16 atoms from the molecule.
      5. Generating the corresponding bond influence matrix.
      
    Each sample contains:
      - features: Tensor of shape (16, 6)
      - bond_influence: Tensor of shape (16, 16)
      - targets: Tensor of shape (16,)
      - v_value: The integer v-value from the molecule's filename.
    '''

    def __init__(self,
                 root,
                 filenames,
                 dataset_size=1000,
                 threshold=2.0,
                 num_atoms_in_sample=16,
                 augmentations=None,
                 processed_dir='./processed',
                 seed=42):
        self.root = root
        if isinstance(filenames, str):
            self.filenames = [filenames]
        else:
            self.filenames = filenames
        self.dataset_size = dataset_size
        self.threshold = threshold
        self.num_atoms_sample = num_atoms_in_sample
        self.augmentations = augmentations
        self.processed_dir = processed_dir

        # Create a unique folder and filename for the processed dataset
        # Folder name from filenames, joined by dashes
        folder_name = "-".join([fn.replace('.csv', '') for fn in self.filenames])
        dataset_dir = os.path.join(self.processed_dir, folder_name)

        if not os.path.exists(dataset_dir):
            os.makedirs(dataset_dir)

        # Create a unique hash for the parameters based on user-specified order
        filenames_str = "".join(self.filenames)
        aug_str = str(self.augmentations is not None)
        params_str = f"{filenames_str}_{dataset_size}_{num_atoms_in_sample}_{self.threshold}_{aug_str}_{seed}"
        params_hash = hashlib.md5(params_str.encode()).hexdigest()
        self.processed_filepath = os.path.join(dataset_dir, f"{params_hash}.pt")

        if os.path.exists(self.processed_filepath):
            print(f"Loading processed dataset from {self.processed_filepath}")
            self.samples = torch.load(self.processed_filepath)
        else:
            print(f"Generating new dataset and saving to {self.processed_filepath}")
            # Process and store each molecule
            self.molecules = []
            for fname in self.filenames:
                filepath = os.path.join(root, fname)
                molecule = self.get_molecule_from_file(filepath)
                if molecule is not None:
                    self.molecules.append(molecule)

            # Precompute each samples
            self.samples = []
            for _ in range(self.dataset_size):
                sample = self.generate_samples()
                self.samples.append(sample)
            
            # Save the dataset
            torch.save(self.samples, self.processed_filepath)

    def __len__(self):
        """
        The length of the dataset is the number of precomputed 16-atom samples. (if num_atoms_sample == 16)
        """
        return len(self.samples)
    
    def __getitem__(self, idx):
        '''
        Retrieve the precomputed 16-atom sample at index idx. (if num_atoms_sample == 16)
        
        Returns:
            dict: {
                'features': Tensor of shape (16, 6),
                'bond_influence': Tensor of shape (16, 16),
                'targets': Tensor of shape (16,),
                'v_value': int
            }
        '''
        return self.samples[idx]

    def get_molecule_from_file(self, filepath):
        '''
        Process a single CSV file to extract features, targets, and bond connectivity.
        
        Returns:
            dict: Contains 'features' (n_atoms x 6), 'targets' (n_atoms,),
                  'bond_adj' (n_atoms x n_atoms), and 'atom_labels' (list).
        '''
        try:
            df = pd.read_csv(filepath)
        except Exception as e:
            print(f'Error reading {filepath}: {e}')
            return None
        
        # Extract v-value from filename:
        basename = os.path.basename(filepath)
        try:
            v_values = int(basename.split('v')[0])
        except ValueError:
            v_values = 0

        features = []
        targets = []
        mms = []
        atom_labels = []
        coords = []

        for _, row in df.iterrows():
            atom_type = row['ATOM'][0]
            one_hot = self.atom_encode(atom_type)
            if one_hot is None:
                continue    # Skip atom types not in the dictionary
            atom_labels.append(atom_type)

            # Get spatial coords
            x, y, z = row['X'], row['Y'], row['Z']
            coords.append([x, y, z])
            features.append(one_hot)
            mm = row['MAGNETIC_MOMENT']
            mms.append(mm)
            targets.append(self.reduce_mm(mm))

        if len(coords) == 0:
            return None
        
        # Normalize coords by subtracting the center
        coords = np.array(coords, dtype=float)
        center = coords.mean(axis=0)
        norm_coords = coords - center

        # Combine the one-hot features with the normalized coordinates
        features = np.hstack([np.array(features, dtype=float), norm_coords])
        features = features.astype(np.float32)
        mms = np.array(mms)
        targets = np.array(targets)

        # Compute the bond connectivity matrix
        adjacency = self.get_adjacency(coords, atom_labels, self.threshold)

        molecule = {
            'features': features,           # (n_atoms, 6)
            'targets': targets,             # (n_atoms,)
            'mms': mms,                     # (n_atoms,)
            'adjacency': adjacency,         # (n_atoms, n_atoms)
            'atom_labels': atom_labels,     # list of length n_atoms
            'v_values': v_values            # number of penta-rings from filename
        }
        return molecule
    
    def get_adjacency(self, coords, atom_labels, threshold=2.0):
        '''
        Compute a bond adjacency matrix given atom coordinates and labels.
        
        Args:
            coords (np.ndarray): Array of shape (n_atoms, 3) with normalized coordinates.
            atom_labels (list): List of atom types (e.g. 'C', 'N', 'O').
            threshold (float): Maximum distance to consider a bond.

        Returns:
            np.ndarray: An (n_atoms x n_atoms) binary matrix where 1 indicates a bond.
        '''
        n = coords.shape[0]
        adjacency = np.zeros((n, n), dtype=int)

        for i in range(n):
            current_label = atom_labels[i]
            distances = []
            for j in range(n):
                if i == j:
                    continue
                dist = self.get_distance(coords[i], coords[j])
                distances.append((dist, j))
            distances.sort(key=lambda x: x[0])
            bonded_atoms = 0

            if current_label == 'C':
                # C forms bonds with up to three nearest atoms (C, N, or O) within threshold.
                for dist, j in distances:
                    if bonded_atoms >= 3:
                        break
                    if dist <= threshold and atom_labels[j] in {'C', 'N', 'O'}:
                        adjacency[i, j] = 1
                        adjacency[j, i] = 1
                        bonded_atoms += 1
            elif current_label == 'N':
                # N forms bonds with up to three nearest carbon atoms within threshold.
                for dist, j in distances:
                    if bonded_atoms >= 3:
                        break
                    if dist <= threshold and atom_labels[j] == 'C':
                        adjacency[i, j] = 1
                        adjacency[j, i] = 1
                        bonded_atoms += 1
            # For oxygen atoms, no explicit bonding rule is defined
        return adjacency

    def get_bond_influence_matrix(self, adjacency, selected_indices):
        '''
        Generate a bond influence matrix for a given set of selected atoms.

        The bond influence matrix is defined as:
            - 1.0 for self connections.
            - For two different atoms, if the shortest path length is s (s > 0),
              then influence = 1/(s^2). If no path exists, influence is 0.

        Args:
            adjacency (np.ndarray): Full bond adjacency matrix.
            selected_indices (list): Indices of the atoms selected

        Returns:
            np.ndarray: A (k x k) bond influence matrix.
        '''
        sp_matrix = self.get_shortest_path(adjacency, selected_indices)
        k = sp_matrix.shape[0]
        influence_matrix = np.zeros((k, k), dtype=float)
        for i in range(k):
            for j in range(k):
                if i == j:
                    influence_matrix[i, j] = 1.0
                elif sp_matrix[i, j] < np.inf and sp_matrix[i, j] > 0:
                    influence_matrix[i, j] = 1.0 / (sp_matrix[i, j] ** 2)
                else:
                    influence_matrix[i, j] = 0.0
        return influence_matrix

    def generate_samples(self):
        '''
        Generate a single 16-atom sample from a randomly selected molecule.
        The procedure is:
          1. Randomly select one molecule from self.molecules.
          2. Apply augmentations (if any) to the molecule.
          3. Randomly sample num_atoms_sample atoms from the molecule.
          4. Compute the bond influence matrix for the selected atoms.
          5. Log the v-value from the source molecule.
        
        Returns:
            dict: A sample with keys 'features', 'bond_influence', 'targets', and 'v'.
        '''
        # Randomly choose a molecule
        molecule = copy.deepcopy(np.random.choice(self.molecules))

        # Save a copy of the original magnetic moment values
        mms = copy.deepcopy(molecule['mms'])

        # Apply augmentations if provided
        if self.augmentations:
            if isinstance(self.augmentations, list):
                for aug in self.augmentations:
                    molecule = aug(molecule)
            else:
                molecule = self.augmentations(molecule)

        # Randomly select <num_atoms_sample> (default to 16) atoms to form the sample
        num_atoms = molecule['features'].shape[0]
        # sample indices: if not enough atoms, sample with replacement
        if num_atoms >= self.num_atoms_sample:
            selected_indices = np.random.choice(num_atoms, self.num_atoms_sample, replace=False)
        else:
            selected_indices = np.random.choice(num_atoms, self.num_atoms_sample, replace=True)

        # Sort indices for consistency
        selected_indices = sorted(selected_indices)

        selected_features = molecule['features'][selected_indices, :]   # (num_atoms_sample, 6)
        selected_targets = molecule['targets'][selected_indices]        # (num_atoms_sample,)
        
        # Retrieve original (unaugmented) MM for the same selected atoms
        selected_mms = mms[selected_indices]
        bond_influence = self.get_bond_influence_matrix(molecule['adjacency'], selected_indices)

        sample = {
            'features': torch.tensor(selected_features, dtype=torch.float),
            'bond_influence': torch.tensor(bond_influence, dtype=torch.float),
            'targets': torch.tensor(selected_targets, dtype=torch.float),
            'mms': torch.tensor(selected_mms, dtype=torch.float),
            'v_value': molecule.get('v_values', 0)  # number of penta-rings
        }

        return sample

    @staticmethod
    def atom_encode(element: str):
        '''
        Convert an element symbol to a one-hot vector
        e.g., 'N' -> (1, 0, 0)
        '''
        if element not in ATOM_DICT:
            return None
        one_hot = [0] * len(ATOM_DICT)
        one_hot[ATOM_DICT[element]] = 1
        return one_hot

    @staticmethod
    def reduce_mm(y):
        '''
        Normalize the magnetic moment using: sign(y) * log(1 + |y|)
        '''
        return np.sign(y) * np.log1p(np.abs(y))
    
    @staticmethod
    def recover_mm(y):
        '''
        Recover original magnetic moment using: sign(y) * (exp(|y'|) - 1)
        '''
        return np.sign(y) * np.expm1(np.abs(y))
    
    @staticmethod
    def get_distance(a1, a2):
        '''
        Distance between atom1 (a1) and atom2 (a2)
        '''
        return np.linalg.norm(a1 - a2)
    
    @staticmethod
    def get_shortest_path(adjacency, selected_indices):
        '''
        Compute the shortest path lengths (in number of bonds) for a subgraph.

        Args:
            adjacency (np.ndarray): Full bond adjacency matrix (n_atoms x n_atoms).
            indices (list): List of indices for the selected atoms.

        Returns:
            np.ndarray: A (k x k) matrix (where k=len(selected_indices)) of shortest path lengths.
        '''
        k = len(selected_indices)
        sp_matrix = np.full((k, k), np.inf)
        for i in range(k):
            sp_matrix[i, i] = 0
        
        # For each selected atom, perform a breadth-first search on the full bond network
        for i, idx in enumerate(selected_indices):
            visited = {idx: 0}
            queue = deque([idx])
            while queue:
                current = queue.popleft()
                current_steps = visited[current]
                # Find neighbors in the full molecule
                neighbors = np.where(adjacency[current] > 0)[0]
                for nb in neighbors:
                    if nb not in visited:
                        visited[nb] = current_steps + 1
                        queue.append(nb)
            # NOTE: Now the visited dict stores the number of paces on the shortest path
            # Update the shortest path lengths for the selected atoms
            for j, jdx in enumerate(selected_indices):
                if jdx in visited:
                    sp_matrix[i, j] = visited[jdx]
        return sp_matrix
    
if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('filenames', nargs='+',
                        help='List of csv files to load.')
    parser.add_argument('-r', '--root', default='./raw',
                        help='Root folder for the data.')
    parser.add_argument('-n', '--num-samples', type=int, default=1000,
                        help='Number of samples to generate.')
    parser.add_argument('-a', '--num-atoms-in-sample', type=int, default=16,
                        help='Number of atoms in a sample.')
    parser.add_argument('-p', '--num-print-samples', type=int, default=1,
                        help='Number of samples to print in the terminal.')
    parser.add_argument('--processed-dir', default='./processed', help='Directory to save/load processed data.')
    parser.add_argument('--seed', type=int, default=42, help='Random seed.')
    parser.add_argument('--batch', action='store_true', help='Enable batch creation of processed datasets.')
    parser.add_argument('--batch-size', type=int, default=1, help='Number of datasets to create in batch mode.')
    args = parser.parse_args()
    
    root = args.root
    filenames = args.filenames
    num_samples = args.num_samples
    num_atoms_in_sample = args.num_atoms_in_sample
    num_print_samples = args.num_print_samples
    
    filenames = [fn + '.csv' for fn in filenames]

    augmentations = [
        OCNRandomTranslation(2.0),
        OCNRandomRotation(),
        OCNRandomReflection(),
        OCNRandomMicroPerturbation(position_noise=0.05, moment_noise=0.5)
    ]

    # Batch creation handling
    if args.batch:
        if args.seed != parser.get_default('seed'):
            print("Warning: batch creation disables explicit seed selection; random seeds will be used per dataset.")
        seeds = [random.randint(0, 2**32 - 1) for _ in range(args.batch_size)]
        for batch_idx, seed_val in enumerate(seeds, start=1):
            print(f"Batch {batch_idx}: using seed {seed_val}")
            dataset = OCNMoleculeDataset(root=root, filenames=filenames, dataset_size=num_samples,
                                        threshold=2.0, num_atoms_in_sample=num_atoms_in_sample,
                                        augmentations=augmentations, processed_dir=args.processed_dir,
                                        seed=seed_val)
    else:
        dataset = OCNMoleculeDataset(root=root, filenames=filenames, dataset_size=num_samples,
                                    threshold=2.0, num_atoms_in_sample=num_atoms_in_sample,
                                    augmentations=augmentations, processed_dir=args.processed_dir,
                                    seed=args.seed)
        for idx in range(num_print_samples):
            sample = dataset[idx]
            print("Features shape:", sample['features'].shape)
            print(sample['features'])
            print("Bond influence matrix shape:", sample['bond_influence'].shape)
            print(sample['bond_influence'])
            print("Targets shape:", sample['targets'].shape)
            print(sample['targets'])
            print("Original targets shape:", sample['mms'].shape)
            print(sample['mms'])
            print("v_value:", sample['v_value'])