{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x21ca3cf0810>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.loader import DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "from preprocessor import AtomDataset\n",
    "from randomizer import augment_data\n",
    "\n",
    "torch.manual_seed(114514)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[56, 6], edge_index=[2, 1], y=[56, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "c:\\Users\\y1hli\\OneDrive - University of North Carolina at Chapel Hill\\github\\CNO-magnetic-moment\\.venv\\Lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset = AtomDataset(root='./', filename='4v.csv', threshold=2.0)\n",
    "data = dataset._data\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000,  0.0000,  0.0000,  4.8525, -3.4187,  0.5181],\n",
       "        [ 1.0000,  0.0000,  0.0000, -7.0737,  3.1019, -0.4405],\n",
       "        [ 1.0000,  0.0000,  0.0000, -7.7450, -1.3922,  0.6709],\n",
       "        [ 1.0000,  0.0000,  0.0000, -8.7569,  4.7177, -0.4788],\n",
       "        [ 1.0000,  0.0000,  0.0000, -5.0400, -3.7536,  0.1928],\n",
       "        [ 1.0000,  0.0000,  0.0000, 10.1274, -3.1242,  0.0387],\n",
       "        [ 1.0000,  0.0000,  0.0000, -7.1443, -3.3862, -0.3235],\n",
       "        [ 1.0000,  0.0000,  0.0000,  9.5193, -1.0333,  0.7964],\n",
       "        [ 1.0000,  0.0000,  0.0000, -4.7967,  3.4600, -0.2781],\n",
       "        [ 1.0000,  0.0000,  0.0000, -1.3578,  1.8579,  1.3817],\n",
       "        [ 1.0000,  0.0000,  0.0000, -2.7252, -0.1465,  1.4743],\n",
       "        [ 1.0000,  0.0000,  0.0000, -5.7876,  1.2395,  0.0477],\n",
       "        [ 1.0000,  0.0000,  0.0000, -2.5002,  3.7407,  0.2625],\n",
       "        [ 1.0000,  0.0000,  0.0000, -3.5885,  1.7466,  0.6790],\n",
       "        [ 1.0000,  0.0000,  0.0000, -4.3634, -1.6946,  1.0379],\n",
       "        [ 1.0000,  0.0000,  0.0000, -0.3060,  3.8474,  0.9339],\n",
       "        [ 1.0000,  0.0000,  0.0000,  7.4965,  0.9904, -0.7733],\n",
       "        [ 1.0000,  0.0000,  0.0000,  6.6393, -4.8241,  0.6163],\n",
       "        [ 1.0000,  0.0000,  0.0000,  4.0396,  4.2718,  0.0186],\n",
       "        [ 1.0000,  0.0000,  0.0000,  5.1632,  0.9829, -0.8522],\n",
       "        [ 1.0000,  0.0000,  0.0000,  6.0783,  2.9622, -0.2133],\n",
       "        [ 1.0000,  0.0000,  0.0000,  2.5454, -3.6149,  0.1339],\n",
       "        [ 1.0000,  0.0000,  0.0000, -0.7493, -1.4563, -1.1714],\n",
       "        [ 1.0000,  0.0000,  0.0000,  0.8529,  0.3896, -1.1402],\n",
       "        [ 1.0000,  0.0000,  0.0000,  3.7580, -1.4899,  0.0252],\n",
       "        [ 1.0000,  0.0000,  0.0000,  0.2382, -3.5660, -0.3733],\n",
       "        [ 1.0000,  0.0000,  0.0000,  1.5240, -1.6760, -0.6300],\n",
       "        [ 1.0000,  0.0000,  0.0000,  2.8302,  1.5979, -0.7337],\n",
       "        [ 1.0000,  0.0000,  0.0000, -1.9710, -3.4054, -0.9287],\n",
       "        [ 1.0000,  0.0000,  0.0000,  9.8008,  1.8114, -0.4364],\n",
       "        [ 0.0000,  1.0000,  0.0000, -9.0178, -1.8736,  0.4537],\n",
       "        [ 0.0000,  1.0000,  0.0000, -7.4154,  4.4272, -0.4368],\n",
       "        [ 0.0000,  1.0000,  0.0000, -5.3728, -2.4661,  0.5038],\n",
       "        [ 0.0000,  1.0000,  0.0000, -6.7883, -2.2224,  0.2920],\n",
       "        [ 0.0000,  1.0000,  0.0000, -8.4089, -3.9277, -0.2896],\n",
       "        [ 0.0000,  1.0000,  0.0000, -6.1673, -4.3403, -0.2836],\n",
       "        [ 0.0000,  1.0000,  0.0000, -5.8200,  2.5834, -0.2242],\n",
       "        [ 0.0000,  1.0000,  0.0000, -3.9852, -0.3889,  1.0149],\n",
       "        [ 0.0000,  1.0000,  0.0000, -1.4222,  3.1195,  0.8607],\n",
       "        [ 0.0000,  1.0000,  0.0000, -3.6210,  3.0299,  0.1993],\n",
       "        [ 0.0000,  1.0000,  0.0000, -4.6138,  0.8343,  0.5162],\n",
       "        [ 0.0000,  1.0000,  0.0000, -2.4660,  1.1482,  1.2304],\n",
       "        [ 0.0000,  1.0000,  0.0000,  8.6704,  1.4810, -0.6188],\n",
       "        [ 0.0000,  1.0000,  0.0000,  5.3004, -4.7167,  0.3761],\n",
       "        [ 0.0000,  1.0000,  0.0000,  4.1675,  1.8681, -0.6216],\n",
       "        [ 0.0000,  1.0000,  0.0000,  6.3209,  1.5966, -0.6156],\n",
       "        [ 0.0000,  1.0000,  0.0000,  6.7953,  4.0262,  0.3401],\n",
       "        [ 0.0000,  1.0000,  0.0000,  4.6668,  3.1303, -0.2482],\n",
       "        [ 0.0000,  1.0000,  0.0000,  3.6391, -2.8381,  0.2073],\n",
       "        [ 0.0000,  1.0000,  0.0000,  2.1777,  0.4085, -0.7919],\n",
       "        [ 0.0000,  1.0000,  0.0000, -0.7949, -2.7739, -0.8330],\n",
       "        [ 0.0000,  1.0000,  0.0000,  1.4280, -2.9930, -0.2836],\n",
       "        [ 0.0000,  1.0000,  0.0000,  2.6541, -0.9155, -0.4340],\n",
       "        [ 0.0000,  1.0000,  0.0000,  0.4451, -0.8819, -1.0191],\n",
       "        [ 0.0000,  0.0000,  1.0000,  8.0683,  3.9495,  0.6510]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m augmented_dataset, original_ys \u001b[38;5;241m=\u001b[39m \u001b[43maugment_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_new_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_noise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmoment_noise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\y1hli\\OneDrive - University of North Carolina at Chapel Hill\\github\\CNO-magnetic-moment\\randomizer.py:192\u001b[0m, in \u001b[0;36maugment_data\u001b[1;34m(data, num_new_data, max_translation, macro_transforms, position_noise, moment_noise, num_micro_per_macro)\u001b[0m\n\u001b[0;32m    188\u001b[0m new_data \u001b[38;5;241m=\u001b[39m macro_randomize(new_data, max_translation, macro_transforms)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_micro_per_macro):\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;66;03m#  Perform perturbations\u001b[39;00m\n\u001b[1;32m--> 192\u001b[0m     perturbed_data, original_y \u001b[38;5;241m=\u001b[39m \u001b[43mmicro_randomize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_noise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmoment_noise\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    193\u001b[0m     randomized_datasets\u001b[38;5;241m.\u001b[39mappend(perturbed_data)\n\u001b[0;32m    194\u001b[0m     original_ys\u001b[38;5;241m.\u001b[39mappend(original_y)\n",
      "File \u001b[1;32mc:\\Users\\y1hli\\OneDrive - University of North Carolina at Chapel Hill\\github\\CNO-magnetic-moment\\randomizer.py:150\u001b[0m, in \u001b[0;36mmicro_randomize\u001b[1;34m(data, position_noise, moment_noise)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;66;03m# perform micro-transform\u001b[39;00m\n\u001b[0;32m    149\u001b[0m transform \u001b[38;5;241m=\u001b[39m RandomMicroPerturbation(position_noise, moment_noise)\n\u001b[1;32m--> 150\u001b[0m randomized_data \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandomized_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;66;03m# record the unaffected magnetic moment\u001b[39;00m\n\u001b[0;32m    153\u001b[0m original_y \u001b[38;5;241m=\u001b[39m transform\u001b[38;5;241m.\u001b[39mget_original_y(randomized_data)\n",
      "File \u001b[1;32mc:\\Users\\y1hli\\OneDrive - University of North Carolina at Chapel Hill\\github\\CNO-magnetic-moment\\randomizer.py:91\u001b[0m, in \u001b[0;36mRandomMicroPerturbation.__call__\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;66;03m# Add noise to coordinates\u001b[39;00m\n\u001b[0;32m     90\u001b[0m noise_coords \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn_like(coords) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_noise\n\u001b[1;32m---> 91\u001b[0m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m:] \u001b[38;5;241m=\u001b[39m coords \u001b[38;5;241m+\u001b[39m noise_coords\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# Add noise to magnetic moments\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;66;03m# data.y typically has shape: (num_atoms,) or (num_atoms, 1)\u001b[39;00m\n\u001b[0;32m     95\u001b[0m noise_moment \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn_like(data\u001b[38;5;241m.\u001b[39my) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmoment_noise\n",
      "File \u001b[1;32mc:\\Users\\y1hli\\OneDrive - University of North Carolina at Chapel Hill\\github\\CNO-magnetic-moment\\.venv\\Lib\\site-packages\\torch_geometric\\data\\data.py:950\u001b[0m, in \u001b[0;36mData.x\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    944\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Iterates over all attributes :obj:`*args` in the data, yielding\u001b[39;00m\n\u001b[0;32m    945\u001b[0m \u001b[38;5;124;03m    their attribute names and values.\u001b[39;00m\n\u001b[0;32m    946\u001b[0m \u001b[38;5;124;03m    If :obj:`*args` is not given, will iterate over all attributes.\u001b[39;00m\n\u001b[0;32m    947\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    948\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_store\u001b[38;5;241m.\u001b[39mitems(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mx\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Tensor]:\n\u001b[0;32m    952\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_store \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    954\u001b[0m \u001b[38;5;129m@x\u001b[39m\u001b[38;5;241m.\u001b[39msetter\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mx\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Optional[Tensor]):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "augmented_dataset, original_ys = augment_data(data=data, num_new_data=50000, position_noise=0.05, moment_noise=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mpl.rcParams['font.family'] = 'arial'\n",
    "mpl.rcParams['font.size'] = 14\n",
    "\n",
    "atom2color = {\n",
    "    0: 'red',   # nitrogen\n",
    "    1: 'blue',  # carbon\n",
    "    2: 'green'  # oxygen\n",
    "}\n",
    "\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "nrows, ncols = 4, 4\n",
    "\n",
    "for idx in range(nrows * ncols):  # Loop through the first 10 datasets\n",
    "    coords = augmented_dataset[idx].x[:, -3:].numpy()\n",
    "    bonds = augmented_dataset[idx].edge_index.numpy()\n",
    "    \n",
    "    # generate color of each atom\n",
    "    atoms_one_hot = augmented_dataset[idx].x[:, :-3].numpy()\n",
    "    atoms = np.argmax(atoms_one_hot, axis=1)\n",
    "    colors = [atom2color[atom_type] for atom_type in atoms]\n",
    "\n",
    "    ax = fig.add_subplot(nrows, ncols, idx + 1, projection='3d')  # Create a 5x2 grid subplot\n",
    "    ax.scatter(coords[:, 0], coords[:, 1], coords[:, 2], color=colors, marker='o')  # Plot atoms\n",
    "\n",
    "    # Plot bonds\n",
    "    for i in range(bonds.shape[1]):\n",
    "        start, end = bonds[:, i]\n",
    "        x_coords = [coords[start, 0], coords[end, 0]]\n",
    "        y_coords = [coords[start, 1], coords[end, 1]]\n",
    "        z_coords = [coords[start, 2], coords[end, 2]]\n",
    "        ax.plot(x_coords, y_coords, z_coords, c='k', linewidth=0.8)\n",
    "        ax.set_xlim(-10, 10)\n",
    "        ax.set_ylim(-10, 10)\n",
    "        ax.set_zlim(-10, 10)\n",
    "        ax.axis('off')\n",
    "\n",
    "plt.subplots_adjust(left=0.05, right=0.95, top=0.95, bottom=0.05, wspace=-0.3, hspace=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNModel(nn.Module):\n",
    "    def __init__(self, in_channels, g_hidden_channels, fc_hidden_channels, out_channels, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, g_hidden_channels)\n",
    "        self.conv2 = GCNConv(g_hidden_channels, g_hidden_channels)\n",
    "        self.conv3 = GCNConv(g_hidden_channels, g_hidden_channels)\n",
    "        \n",
    "        self.fc1 = Linear(g_hidden_channels, fc_hidden_channels)\n",
    "        self.fc2 = Linear(fc_hidden_channels, fc_hidden_channels)\n",
    "        self.fc3 = Linear(fc_hidden_channels, out_channels)\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, edge_index, batch=None):\n",
    "        # x: (num_nodes, in_channels)\n",
    "        # edge_index: (2, E)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        \n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def save_model(self, file_path: str = 'gnn_model.pt'):\n",
    "        torch.save(self.state_dict(), file_path)\n",
    "        print(f'Model saved to {file_path}.')\n",
    "\n",
    "    @staticmethod\n",
    "    def load_model(file_path: str,\n",
    "                   in_channels: int,\n",
    "                   g_hidden_channels: int,\n",
    "                   fc_hidden_channels: int,\n",
    "                   out_channels: int,\n",
    "                   dropout=0.0):\n",
    "        model = GNNModel(in_channels, g_hidden_channels, fc_hidden_channels, out_channels, dropout)\n",
    "        model.load_state_dict(torch.load(file_path))\n",
    "        print(f'Model loaded from {file_path}.')\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(augmented_dataset)\n",
    "\n",
    "train_size = int(0.8 * len(augmented_dataset))\n",
    "train_dataset = augmented_dataset[:train_size]\n",
    "test_dataset = augmented_dataset[train_size:]\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=2048, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2048, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mse(pred, target):\n",
    "    return F.mse_loss(pred, target)\n",
    "\n",
    "def compute_r2(pred, target):\n",
    "    \"\"\"\n",
    "    R^2 = 1 - [sum((y - y_pred)^2) / sum((y - mean(y))^2)]\n",
    "    \"\"\"\n",
    "    # flatten to 1d\n",
    "    pred = pred.view(-1)\n",
    "    target = target.view(-1)\n",
    "\n",
    "    ss_res = torch.sum((target - pred) ** 2)\n",
    "    ss_tot = torch.sum((target - torch.mean(target)) ** 2)\n",
    "    if ss_tot.item() == 0:\n",
    "        # Edge case: if all target values are the same\n",
    "        return torch.tensor(1.0) if ss_res.item == 0 else torch.tensor(0.0)\n",
    "    \n",
    "    r2 = 1 - ss_res / ss_tot\n",
    "    return r2\n",
    "\n",
    "class SignConstrainedMSELoss(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    A custom loss that applies MSE but heavily panalizes predictions with the wrong sign\n",
    "\n",
    "    Args:\n",
    "        penalty_factor (float): Multiplier (lambda) for sign mismatch\n",
    "                                Loss = MSE(pred, y) + lambda * SignMismatchPenalty(pred, y)\n",
    "    \"\"\"\n",
    "    def __init__(self, panelty_factor, soft_zone):\n",
    "        super().__init__()\n",
    "        self.panelty_factor = panelty_factor\n",
    "        self.soft_zone = soft_zone\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        \"\"\"\n",
    "        y_pred, y_true: shape (N,) or (N, 1).\n",
    "        Do a standard MSE plus the sign mismatch panelty if sign(y_pred) != sign(y_true)\n",
    "        \"\"\"\n",
    "        # Flatten to (N,) if necessary\n",
    "        y_pred = y_pred.view(-1)\n",
    "        y_true = y_true.view(-1)\n",
    "\n",
    "        # compute base MSE\n",
    "        mse_loss = F.mse_loss(y_pred, y_true)\n",
    "        \n",
    "        # sign mismatch panelty\n",
    "        mismatch_neg = (y_true < -self.soft_zone) & (y_pred > 0)\n",
    "        mismatch_pos = (y_true >  self.soft_zone) & (y_pred < 0)\n",
    "        mismatch = mismatch_neg | mismatch_pos\n",
    "\n",
    "        panelty = self._sign_mismatch_panelty(y_pred, mismatch)\n",
    "        \n",
    "        total_loss = mse_loss + torch.mean(panelty)\n",
    "        return total_loss\n",
    "\n",
    "    def _sign_mismatch_panelty(self, y_pred, mismatch):\n",
    "        \"\"\"\n",
    "        panelty = panelty_factor * abs(y_pred)\n",
    "        \"\"\"\n",
    "        panelty = torch.zeros_like(y_pred)\n",
    "        panelty[mismatch] = self.panelty_factor * torch.abs(y_pred[mismatch])\n",
    "        return panelty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "epochs = 100\n",
    "\n",
    "model = GNNModel(\n",
    "    in_channels=6,\n",
    "    g_hidden_channels=64,\n",
    "    fc_hidden_channels=64,\n",
    "    out_channels=1,\n",
    "    dropout=0.05\n",
    ")\n",
    "sign_constrained_mse = SignConstrainedMSELoss(panelty_factor=5, soft_zone=0.01)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "model = model.to(device)\n",
    "\n",
    "print(model)\n",
    "print(sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_train_losses = []\n",
    "avg_test_losses = []\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    # Train\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    for batch_data in train_loader:\n",
    "        batch_data = batch_data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        out = model(batch_data.x, batch_data.edge_index, batch_data.batch)\n",
    "        # flatten to (num_nodes,) if out has shape (num_nodes, 1)\n",
    "        if out.shape[-1] == 1:\n",
    "            out = out.view(-1)\n",
    "        y = batch_data.y.view(-1)\n",
    "\n",
    "        train_loss = sign_constrained_mse(out, y)\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_losses.append(train_loss.item())\n",
    "    \n",
    "    avg_train_loss = sum(train_losses) / len(train_losses)\n",
    "    avg_train_losses.append(avg_train_loss)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    test_losses = []\n",
    "    test_r2_scores = []\n",
    "    with torch.no_grad():\n",
    "        for batch_data in test_loader:\n",
    "            batch_data = batch_data.to(device)\n",
    "            out = model(batch_data.x, batch_data.edge_index, batch_data.batch)\n",
    "            if out.shape[-1] == 1:\n",
    "                out = out.view(-1)\n",
    "            y = batch_data.y.view(-1)\n",
    "\n",
    "            test_loss = sign_constrained_mse(out, y)\n",
    "            r2 = compute_r2(out, y)\n",
    "\n",
    "            test_losses.append(test_loss.item())\n",
    "            test_r2_scores.append(r2.item())\n",
    "\n",
    "    scheduler.step(test_loss)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "    avg_test_loss = sum(test_losses) / len(test_losses)\n",
    "    avg_test_r2 = sum(test_r2_scores) / len(test_r2_scores)\n",
    "    avg_test_losses.append(avg_test_loss)\n",
    "\n",
    "    print(f\"Epoch [{epoch}/{epochs}] \"\n",
    "          f\"Train MSE: {avg_train_loss:.4f} | \"\n",
    "          f\"Test MSE: {avg_test_loss:.4f}, Test R^2: {avg_test_r2:.4f} | \"\n",
    "          f\"LR: {current_lr:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model()\n",
    "np.save('train_losses.npy', avg_train_losses)\n",
    "np.save('validation_losses.npy', avg_test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_train_losses = np.load('train_losses.npy')\n",
    "avg_test_losses = np.load('validation_losses.npy')\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "\n",
    "plt.plot(avg_train_losses, label='train')\n",
    "plt.plot(avg_test_losses, label='validation')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Sign Contrained Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GNNModel.load_model('gnn_model.pt',\n",
    "                             in_channels=6,\n",
    "                             g_hidden_channels=64,\n",
    "                             fc_hidden_channels=64,\n",
    "                             out_channels=1,\n",
    "                             dropout=0.05)\n",
    "\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "all_preds = []\n",
    "all_truth = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_data in train_loader:\n",
    "        batch_data = batch_data.to(device)\n",
    "\n",
    "        out = model(batch_data.x, batch_data.edge_index, batch_data.batch)\n",
    "\n",
    "        out_flat = out.view(-1).cpu().numpy()\n",
    "        y_flat = batch_data.y.view(-1).cpu().numpy()\n",
    "\n",
    "        all_preds.append(out_flat)\n",
    "        all_truth.append(y_flat)\n",
    "\n",
    "predictions = np.concatenate(all_preds, axis=0)\n",
    "ground_truth = np.concatenate(all_truth, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.plot(predictions, c='violet', label='predicted')\n",
    "plt.plot(ground_truth, c='purple', label='ground truth')\n",
    "plt.plot(np.zeros_like(predictions), ls='--', c='g')\n",
    "\n",
    "plt.xlim(1000, 1200)\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sample = len(ground_truth)\n",
    "\n",
    "plt.figure(figsize=(10, 2.5))\n",
    "plt.plot(ground_truth - predictions, 'o', c='gray', ms=0.1)\n",
    "plt.ticklabel_format(axis='x', style='plain')\n",
    "plt.xlim(0, num_sample)\n",
    "plt.xticks([0, num_sample / 2, num_sample])\n",
    "plt.xlabel('# of samples')\n",
    "plt.ylabel('difference')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ground_truth - predictions, bins=1000)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
